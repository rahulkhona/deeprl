{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the third project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = UnityEnvironment(file_name=\"./Tennis.app\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1.  If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01.  Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agents and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agents' performance, if they select actions at random with each time step.  A window should pop up that allows you to observe the agents.\n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agents are able to use their experiences to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 6):                                      # play game for 5 episodes\n",
    "    env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "    states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "    scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "    while True:\n",
    "        actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "        actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "        env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "        next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "        rewards = env_info.rewards                         # get reward (for each agent)\n",
    "        dones = env_info.local_done                        # see if episode finished\n",
    "        scores += env_info.rewards                         # update the score (for each agent)\n",
    "        print(\"actions type\", type(actions), \"states type\", type(next_states), \"rewards type\", type(rewards), \"dones type\", type(dones))\n",
    "        print(np.asarray(rewards))\n",
    "        print(np.asarray(dones))\n",
    "        print(\"actions shape\", actions.shape)\n",
    "        print(\"states sahpe\", next_states.shape)\n",
    "        print(\"rewards shape\", np.asarray(rewards).shape)\n",
    "        print(\"dones shape\", np.asarray(dones).shape)\n",
    "        \n",
    "        break\n",
    "        states = next_states                               # roll over states to next time step\n",
    "        if np.any(dones):                                  # exit loop if episode finished\n",
    "            break\n",
    "    print('Score (max over agents) from episode {}: {}'.format(i, np.max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "from agent import MADDPGAgent\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import os\n",
    "import constants as C\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(scores, image_folder):\n",
    "    x = np.arange(len(scores))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_ylabel(\"episode scores\")\n",
    "    ax.set_xlabel(\"epidsode number\")\n",
    "    plt.ylim((0, 5))\n",
    "    plt.plot(x, scores)\n",
    "    if image_folder:\n",
    "        plt.savefig(os.path.join(image_folder, \"plot.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(seed:int=0x10020303):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    env = UnityEnvironment(file_name=\"./Tennis.app\", no_graphics=True)\n",
    "    brain_name = env.brain_names[0]\n",
    "    brain = env.brains[brain_name]\n",
    "    env_info = env.reset(train_mode=True)[brain_name]\n",
    "    num_agents = len(env_info.agents)\n",
    "    action_size = brain.vector_action_space_size\n",
    "    states = env_info.vector_observations\n",
    "    state_size = states.shape[1]\n",
    "\n",
    "    device = 'cpu' if not torch.cuda.is_available() else \"cuda\"\n",
    "\n",
    "    agent = MADDPGAgent(num_agents, state_size, action_size)\n",
    "\n",
    "    scores = []\n",
    "    scores_window = deque(maxlen=C.SCORES_WINDOW_LENGTH)\n",
    "    print(\"Starting training\")\n",
    "    steps = 0\n",
    "    for i in range(1, C.NUM_EPISDOES + 1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        agent.reset()\n",
    "        obs = env_info.vector_observations\n",
    "        score = np.zeros(num_agents)\n",
    "\n",
    "        while True:\n",
    "            actions = agent.choose_actions(torch.from_numpy(obs).float().to(device), True if i < 100000 else False)\n",
    "            #actions = np.asarray([np.random.uniform(-1, 1, 2), np.random.uniform(-1, 1, 2)])\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            rewards = np.asarray(env_info.rewards)\n",
    "            rewards *= 10\n",
    "            dones = np.array(env_info.local_done).astype(np.uint8)\n",
    "            next_obs = env_info.vector_observations\n",
    "            agent.step(obs, actions, rewards , next_obs, dones)\n",
    "            obs = next_obs\n",
    "            score += rewards\n",
    "            steps += 1\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        scores.append(np.max(score))\n",
    "        scores_window.append(np.max(score))\n",
    "        if len(scores_window) == C.SCORES_WINDOW_LENGTH and np.mean(scores_window) > C.WINNING_AVG:\n",
    "            print(f\"solved environment in {i} episodes with avg score of {np.mean(scores_window)}\")\n",
    "            agent.save(\"./\")\n",
    "            env.close()\n",
    "            return scores, scores_window, True, i\n",
    "        if i % C.PRINT_EVERY == 0:\n",
    "            print(f\"completed {i} episodes and average score is {np.mean(scores_window)} average steps per episode {steps/i}\", end=\"\\n\")\n",
    "    \n",
    "    env.close()\n",
    "    return scores, scores_window, False, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mono path[0] = '/Users/rkhona/learn/deeprl/tennis/Tennis.app/Contents/Resources/Data/Managed'\n",
      "Mono config path = '/Users/rkhona/learn/deeprl/tennis/Tennis.app/Contents/MonoBleedingEdge/etc'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training\n",
      "completed 10 episodes and average score is 0.0 average steps per episode 14.5\n",
      "completed 20 episodes and average score is 0.05000000074505806 average steps per episode 15.25\n",
      "completed 30 episodes and average score is 0.06666666766007741 average steps per episode 16.133333333333333\n",
      "completed 40 episodes and average score is 0.07250000117346644 average steps per episode 16.075\n",
      "completed 50 episodes and average score is 0.07600000128149986 average steps per episode 16.02\n",
      "completed 60 episodes and average score is 0.09333333497246106 average steps per episode 16.283333333333335\n",
      "completed 70 episodes and average score is 0.09285714450691428 average steps per episode 16.2\n",
      "completed 80 episodes and average score is 0.08125000144354999 average steps per episode 15.95\n",
      "completed 90 episodes and average score is 0.07222222350537777 average steps per episode 15.755555555555556\n",
      "completed 100 episodes and average score is 0.06500000115483999 average steps per episode 15.6\n",
      "completed 110 episodes and average score is 0.0830000014975667 average steps per episode 15.763636363636364\n",
      "completed 120 episodes and average score is 0.07300000134855508 average steps per episode 15.633333333333333\n",
      "completed 130 episodes and average score is 0.06300000119954348 average steps per episode 15.523076923076923\n",
      "completed 140 episodes and average score is 0.054000001028180124 average steps per episode 15.428571428571429\n",
      "completed 150 episodes and average score is 0.04500000085681677 average steps per episode 15.346666666666666\n",
      "completed 160 episodes and average score is 0.027000000514090062 average steps per episode 15.275\n",
      "completed 170 episodes and average score is 0.018000000342726707 average steps per episode 15.211764705882352\n",
      "completed 180 episodes and average score is 0.018000000342726707 average steps per episode 15.155555555555555\n",
      "completed 190 episodes and average score is 0.018000000342726707 average steps per episode 15.105263157894736\n",
      "completed 200 episodes and average score is 0.018000000342726707 average steps per episode 15.06\n",
      "completed 210 episodes and average score is 0.0 average steps per episode 15.019047619047619\n",
      "completed 220 episodes and average score is 0.0 average steps per episode 14.981818181818182\n",
      "completed 230 episodes and average score is 0.0 average steps per episode 14.947826086956521\n",
      "completed 240 episodes and average score is 0.0 average steps per episode 14.916666666666666\n",
      "completed 250 episodes and average score is 0.0 average steps per episode 14.888\n",
      "completed 260 episodes and average score is 0.0 average steps per episode 14.861538461538462\n",
      "completed 270 episodes and average score is 0.0 average steps per episode 14.837037037037037\n",
      "completed 280 episodes and average score is 0.0 average steps per episode 14.814285714285715\n",
      "completed 290 episodes and average score is 0.0 average steps per episode 14.793103448275861\n",
      "completed 300 episodes and average score is 0.0 average steps per episode 14.773333333333333\n",
      "completed 310 episodes and average score is 0.0 average steps per episode 14.754838709677419\n",
      "completed 320 episodes and average score is 0.0 average steps per episode 14.7375\n",
      "completed 330 episodes and average score is 0.0 average steps per episode 14.72121212121212\n",
      "completed 340 episodes and average score is 0.0 average steps per episode 14.705882352941176\n",
      "completed 350 episodes and average score is 0.0 average steps per episode 14.691428571428572\n",
      "completed 360 episodes and average score is 0.0 average steps per episode 14.677777777777777\n",
      "completed 370 episodes and average score is 0.0 average steps per episode 14.664864864864866\n",
      "completed 380 episodes and average score is 0.0 average steps per episode 14.652631578947368\n",
      "completed 390 episodes and average score is 0.0 average steps per episode 14.64102564102564\n",
      "completed 400 episodes and average score is 0.0 average steps per episode 14.63\n",
      "completed 410 episodes and average score is 0.0 average steps per episode 14.61951219512195\n",
      "completed 420 episodes and average score is 0.0 average steps per episode 14.60952380952381\n",
      "completed 430 episodes and average score is 0.0 average steps per episode 14.6\n",
      "completed 440 episodes and average score is 0.0 average steps per episode 14.590909090909092\n",
      "completed 450 episodes and average score is 0.0 average steps per episode 14.582222222222223\n",
      "completed 460 episodes and average score is 0.0 average steps per episode 14.57391304347826\n",
      "completed 470 episodes and average score is 0.0 average steps per episode 14.565957446808511\n",
      "completed 480 episodes and average score is 0.0 average steps per episode 14.558333333333334\n",
      "completed 490 episodes and average score is 0.0 average steps per episode 14.551020408163266\n",
      "completed 500 episodes and average score is 0.0 average steps per episode 14.544\n",
      "completed 510 episodes and average score is 0.0 average steps per episode 14.537254901960784\n",
      "completed 520 episodes and average score is 0.0 average steps per episode 14.53076923076923\n",
      "completed 530 episodes and average score is 0.0 average steps per episode 14.524528301886793\n",
      "completed 540 episodes and average score is 0.0 average steps per episode 14.518518518518519\n",
      "completed 550 episodes and average score is 0.0 average steps per episode 14.512727272727274\n",
      "completed 560 episodes and average score is 0.0 average steps per episode 14.507142857142858\n",
      "completed 570 episodes and average score is 0.0 average steps per episode 14.501754385964912\n",
      "completed 580 episodes and average score is 0.0 average steps per episode 14.49655172413793\n",
      "completed 590 episodes and average score is 0.009000000171363353 average steps per episode 14.520338983050847\n",
      "completed 600 episodes and average score is 0.036000000685453414 average steps per episode 14.603333333333333\n",
      "completed 610 episodes and average score is 0.036000000685453414 average steps per episode 14.59672131147541\n",
      "completed 620 episodes and average score is 0.046000000834465024 average steps per episode 14.620967741935484\n",
      "completed 630 episodes and average score is 0.05600000098347664 average steps per episode 14.644444444444444\n",
      "completed 640 episodes and average score is 0.05600000098347664 average steps per episode 14.6375\n",
      "completed 650 episodes and average score is 0.05600000098347664 average steps per episode 14.63076923076923\n",
      "completed 660 episodes and average score is 0.07500000130385161 average steps per episode 14.68030303030303\n",
      "completed 670 episodes and average score is 0.07500000130385161 average steps per episode 14.67313432835821\n",
      "completed 680 episodes and average score is 0.08500000145286321 average steps per episode 14.694117647058823\n",
      "completed 690 episodes and average score is 0.07600000128149986 average steps per episode 14.68695652173913\n",
      "completed 700 episodes and average score is 0.059000000916421415 average steps per episode 14.707142857142857\n",
      "completed 710 episodes and average score is 0.059000000916421415 average steps per episode 14.701408450704225\n",
      "completed 720 episodes and average score is 0.059000000916421415 average steps per episode 14.722222222222221\n",
      "completed 730 episodes and average score is 0.049000000767409804 average steps per episode 14.715068493150685\n",
      "completed 740 episodes and average score is 0.059000000916421415 average steps per episode 14.758108108108107\n",
      "completed 750 episodes and average score is 0.09500000160187483 average steps per episode 14.848\n",
      "completed 760 episodes and average score is 0.08500000145286321 average steps per episode 14.861842105263158\n",
      "completed 770 episodes and average score is 0.08500000145286321 average steps per episode 14.853246753246752\n",
      "completed 780 episodes and average score is 0.09300000164657832 average steps per episode 14.89102564102564\n",
      "completed 790 episodes and average score is 0.11100000198930501 average steps per episode 14.927848101265823\n",
      "completed 800 episodes and average score is 0.11900000218302012 average steps per episode 14.965\n",
      "completed 810 episodes and average score is 0.11900000218302012 average steps per episode 14.955555555555556\n",
      "completed 820 episodes and average score is 0.1090000020340085 average steps per episode 14.946341463414635\n",
      "completed 830 episodes and average score is 0.1090000020340085 average steps per episode 14.937349397590362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed 840 episodes and average score is 0.10800000205636025 average steps per episode 14.948809523809524\n",
      "completed 850 episodes and average score is 0.09100000169128179 average steps per episode 14.98\n",
      "completed 860 episodes and average score is 0.11800000220537185 average steps per episode 15.054651162790698\n",
      "completed 870 episodes and average score is 0.16300000306218862 average steps per episode 15.14367816091954\n",
      "completed 880 episodes and average score is 0.19900000374764204 average steps per episode 15.243181818181819\n",
      "completed 890 episodes and average score is 0.21700000409036874 average steps per episode 15.304494382022472\n",
      "completed 900 episodes and average score is 0.2080000039190054 average steps per episode 15.307777777777778\n",
      "completed 910 episodes and average score is 0.2360000044107437 average steps per episode 15.348351648351649\n",
      "completed 920 episodes and average score is 0.2540000047534704 average steps per episode 15.369565217391305\n",
      "completed 930 episodes and average score is 0.2630000049248338 average steps per episode 15.374193548387098\n",
      "completed 940 episodes and average score is 0.28100000526756047 average steps per episode 15.418085106382978\n",
      "completed 950 episodes and average score is 0.34400000646710394 average steps per episode 15.56\n",
      "completed 960 episodes and average score is 0.3620000068098307 average steps per episode 15.653125\n",
      "completed 970 episodes and average score is 0.3350000062957406 average steps per episode 15.67319587628866\n",
      "completed 980 episodes and average score is 0.3170000059530139 average steps per episode 15.726530612244899\n",
      "completed 990 episodes and average score is 0.3530000066384673 average steps per episode 15.847474747474747\n",
      "completed 1000 episodes and average score is 0.3530000066384673 average steps per episode 15.848\n",
      "completed 1010 episodes and average score is 0.37000000700354574 average steps per episode 15.928712871287129\n",
      "completed 1020 episodes and average score is 0.3880000073462725 average steps per episode 15.97549019607843\n",
      "completed 1030 episodes and average score is 0.4150000078603625 average steps per episode 16.023300970873787\n",
      "completed 1040 episodes and average score is 0.4150000078603625 average steps per episode 16.05480769230769\n",
      "completed 1050 episodes and average score is 0.37800000719726085 average steps per episode 16.11809523809524\n",
      "completed 1060 episodes and average score is 0.3870000073686242 average steps per episode 16.206603773584906\n",
      "completed 1070 episodes and average score is 0.432000008225441 average steps per episode 16.298130841121495\n",
      "completed 1080 episodes and average score is 0.4410000083968043 average steps per episode 16.35648148148148\n",
      "completed 1090 episodes and average score is 0.4230000080540776 average steps per episode 16.428440366972477\n",
      "completed 1100 episodes and average score is 0.45900000873953106 average steps per episode 16.486363636363638\n",
      "completed 1110 episodes and average score is 0.4680000089108944 average steps per episode 16.555855855855857\n",
      "completed 1120 episodes and average score is 0.4860000092536211 average steps per episode 16.623214285714287\n",
      "solved environment in 1122 episodes with avg score of 0.505000009573996\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores, score_window, solved, iterations = run()\n",
    "if solved:\n",
    "        plot(scores, \"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
